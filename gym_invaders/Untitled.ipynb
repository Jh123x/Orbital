{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ai_invader.model import EvolutionaryAI\n",
    "import pygad.cnn as cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6624307502745201"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (120, 160,4)\n",
    "input_shape1 = (4,120,160)\n",
    "num_actions = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer = cnn.Input2D(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv_layer1 = cnn.Conv2D(num_filters=31,\n",
    "                              kernel_size=8,\n",
    "                              previous_layer=input_layer,\n",
    "                              activation_function=None)\n",
    "\n",
    "relu_layer1 = cnn.ReLU(previous_layer=conv_layer1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer2 = cnn.Conv2D(num_filters=2,\n",
    "                              kernel_size=4,\n",
    "                              previous_layer=relu_layer1,\n",
    "                              activation_function=None)\n",
    "relu_layer2 = cnn.ReLU(previous_layer=conv_layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pooling_layer = cnn.MaxPooling2D(pool_size=4,\n",
    "                                          previous_layer=relu_layer2,\n",
    "                                          stride=2)\n",
    "conv_layer3 = cnn.Conv2D(num_filters=3,\n",
    "                              kernel_size=3,\n",
    "                              previous_layer=max_pooling_layer,\n",
    "                              activation_function=None)\n",
    "relu_layer3 = cnn.ReLU(previous_layer=conv_layer3)\n",
    "flatten = cnn.Flatten(previous_layer=relu_layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dense_layer1 = cnn.Dense(num_neurons=128,\n",
    "                              previous_layer=flatten,\n",
    "                              activation_function='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer2 = cnn.Dense(num_neurons=num_actions,\n",
    "                              previous_layer=dense_layer1,\n",
    "                              activation_function='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = cnn.Model(last_layer=dense_layer2,learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(*(4, 160, 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feed_sample(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-c4d57f26149f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-c4d57f26149f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    convolve2d(, in2, mode='full', boundary='fill', fillvalue=0)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "convolve2d(, in2, mode='full', boundary='fill', fillvalue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(510, 510)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import signal\n",
    "from scipy import misc\n",
    "ascent = misc.ascent()\n",
    "print(ascent.shape)\n",
    "scharr = np.array([[ -3-3j, 0-10j,  +3 -3j],\n",
    "                   [-10+0j, 0+ 0j, +10 +0j],\n",
    "                   [ -3+3j, 0+10j,  +3 +3j]])\n",
    "print(scharr.shape) # Gx + j*Gy\n",
    "grad = signal.convolve2d(ascent, scharr, boundary='symm', mode='valid')\n",
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (512,512,1)\n",
    "\n",
    "input_layer = cnn.Input2D(input_shape=input_shape)\n",
    "conv_test = cnn.Conv2D(num_filters=1,\n",
    "                              kernel_size=3,\n",
    "                              previous_layer=input_layer,\n",
    "                              activation_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascent2 = np.expand_dims(misc.ascent(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascent2.shape\n",
    "# acent2_tst = np.squeeze(ascent2,2)\n",
    "acent2_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterer = np.squeeze(conv_test.trained_weights[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = np.expand_dims(result,2).shape\n",
    "# result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-8754fad37acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                            conv_test.filter_bank_size[1] / 2.0), :]\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-8754fad37acb>\u001b[0m in \u001b[0;36mclipping\u001b[0;34m(res, conv_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconv_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_bank_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     final_result = result[np.uint16(conv_test.filter_bank_size[1] / 2.0):result.shape[0] - np.uint16(\n\u001b[0m\u001b[1;32m      4\u001b[0m                         conv_test.filter_bank_size[1] / 2.0),\n\u001b[1;32m      5\u001b[0m                        np.uint16(conv_test.filter_bank_size[1] / 2.0):result.shape[1] - np.uint16(\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "conv_test.filter_bank_size[1]/2\n",
    "def clipping(res, conv_test):\n",
    "    final_result = result[np.uint16(conv_test.filter_bank_size[1] / 2.0):result.shape[0] - np.uint16(\n",
    "                        conv_test.filter_bank_size[1] / 2.0),\n",
    "                       np.uint16(conv_test.filter_bank_size[1] / 2.0):result.shape[1] - np.uint16(\n",
    "                           conv_test.filter_bank_size[1] / 2.0), :]\n",
    "    return final_result\n",
    "clipping(ex,conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2982785756296037"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_test.trained_weights[0]\n",
    "np.sum(conv_test.trained_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 ms, sys: 1.35 ms, total: 15.8 ms\n",
      "Wall time: 14.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[24.58039646, 24.63053114, 24.75712178, ..., 34.89859335,\n",
       "        34.89859335, 34.89859335],\n",
       "       [24.59280191, 24.74791435, 24.75712178, ..., 34.89859335,\n",
       "        34.89859335, 34.89859335],\n",
       "       [24.53014033, 24.67897744, 24.68185548, ..., 34.89859335,\n",
       "        34.89859335, 34.89859335],\n",
       "       ...,\n",
       "       [52.53968053, 52.53968053, 52.53968053, ..., 16.10070688,\n",
       "        17.50210277, 18.7349232 ],\n",
       "       [52.9493865 , 52.9493865 , 52.9493865 , ..., 15.84734327,\n",
       "        16.55079303, 17.57491117],\n",
       "       [53.09358646, 53.09358646, 53.09358646, ..., 15.06362838,\n",
       "        15.53337169, 17.24158311]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time result = convolve2d(acent2_tst,filterer,boundary='symm', mode='valid')\n",
    "result\n",
    "\n",
    "# result = result[np.uint16(self.filter_bank_size[1] / 2.0):result.shape[0] - np.uint16(\n",
    "#                 self.filter_bank_size[1] / 2.0),\n",
    "#                 np.uint16(self.filter_bank_size[1] / 2.0):result.shape[1] - np.uint16(\n",
    "#                 self.filter_bank_size[1] / 2.0), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26555465,  0.01524082,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.32760646,  0.19318587,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.06872755,  0.02663442, -0.13888643, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.3342822 , -0.3342822 , -0.3342822 , ...,  0.02573997,\n",
       "         0.80021441, -1.57742661],\n",
       "       [-0.1114274 , -0.1114274 , -0.1114274 , ...,  1.57806327,\n",
       "        -0.3661163 , -0.01186352],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  4.14487881,\n",
       "        -0.27913723,  0.42825888]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result-np.squeeze(n,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.66 s, sys: 43.1 ms, total: 6.7 s\n",
      "Wall time: 6.77 s\n"
     ]
    }
   ],
   "source": [
    "%time n = conv_test.conv_(ascent2, conv_test.trained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510, 510, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.31484181, 24.61529032, 24.75712178, ..., 34.89859335,\n",
       "        34.89859335, 34.89859335],\n",
       "       [24.26519545, 24.55472848, 24.75712178, ..., 34.89859335,\n",
       "        34.89859335, 34.89859335],\n",
       "       [24.59886788, 24.65234302, 24.82074191, ..., 34.89859335,\n",
       "        34.89859335, 34.89859335],\n",
       "       ...,\n",
       "       [52.87396273, 52.87396273, 52.87396273, ..., 16.07496691,\n",
       "        16.70188835, 20.31234981],\n",
       "       [53.06081391, 53.06081391, 53.06081391, ..., 14.26927999,\n",
       "        16.91690933, 17.58677468],\n",
       "       [53.09358646, 53.09358646, 53.09358646, ..., 10.91874957,\n",
       "        15.81250892, 16.81332423]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(n,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ai_invader.model.CNN2D import Conv2DImproved\n",
    "import numpy as np\n",
    "import pygad.cnn as cnn\n",
    "from scipy.signal import convolve2d\n",
    "class Conv2DImproved(cnn.Conv2D):\n",
    "    def __init__(self,num_filters, kernel_size, previous_layer, activation_function=None):\n",
    "        super(Conv2DImproved,self).__init__(num_filters,kernel_size,previous_layer,activation_function)\n",
    "\n",
    "    def conv_(self, input2D, conv_filter):\n",
    "        result = np.zeros(shape=(input2D.shape[0]-self.kernel_size+1, input2D.shape[1]-self.kernel_size+1, conv_filter.shape[0]))\n",
    "        input2D = np.squeeze(input2D)\n",
    "        for filter_idx in range(conv_filter.shape[0]):\n",
    "            # for each filter in the stack of filters\n",
    "            filt = np.squeeze(conv_filter[filter_idx], 2)\n",
    "            # squeeze last axis of filter off for scipy\n",
    "            #print(filt.shape)\n",
    "            #print(input2D.shape)\n",
    "            conv = convolve2d(input2D,filt,boundary='symm', mode='valid')\n",
    "            result[:,:,filter_idx]= conv\n",
    "\n",
    "        final_result = result[np.uint16(self.filter_bank_size[1] / 2.0):result.shape[0] - np.uint16(\n",
    "                                self.filter_bank_size[1] / 2.0),\n",
    "                                np.uint16(self.filter_bank_size[1] / 2.0):result.shape[1] - np.uint16(\n",
    "                                self.filter_bank_size[1] / 2.0), :]\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = cnn.Input2D(input_shape=input_shape)\n",
    "conv_test = Conv2DImproved(num_filters=2,\n",
    "                              kernel_size=3,\n",
    "                              previous_layer=input_layer,\n",
    "                              activation_function=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510, 510, 2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_test.layer_output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 1)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.squeeze(ascent2).shape\n",
    "input_layer.layer_output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[32.69206787, -3.01081896],\n",
       "        [32.96940034, -3.19026409],\n",
       "        [32.96940034, -3.19026409],\n",
       "        ...,\n",
       "        [46.47493783, -4.49711926],\n",
       "        [46.47493783, -4.49711926],\n",
       "        [46.47493783, -4.49711926]],\n",
       "\n",
       "       [[32.74763069, -3.15321191],\n",
       "        [32.89017195, -3.16292914],\n",
       "        [33.00816627, -3.2613198 ],\n",
       "        ...,\n",
       "        [46.47493783, -4.49711926],\n",
       "        [46.47493783, -4.49711926],\n",
       "        [46.47493783, -4.49711926]],\n",
       "\n",
       "       [[32.72116104, -3.14925399],\n",
       "        [33.08069362, -3.07919437],\n",
       "        [32.97417558, -3.34796744],\n",
       "        ...,\n",
       "        [46.47493783, -4.49711926],\n",
       "        [46.47493783, -4.49711926],\n",
       "        [46.47493783, -4.49711926]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[69.92785078, -6.70878865],\n",
       "        [69.92785078, -6.70878865],\n",
       "        [69.92785078, -6.70878865],\n",
       "        ...,\n",
       "        [19.06417349,  0.99493772],\n",
       "        [22.52933292, -1.86833482],\n",
       "        [23.33454264, -2.097251  ]],\n",
       "\n",
       "       [[70.04878934, -6.92446439],\n",
       "        [70.04878934, -6.92446439],\n",
       "        [70.04878934, -6.92446439],\n",
       "        ...,\n",
       "        [16.34051942,  0.4332377 ],\n",
       "        [21.52569293, -0.89411782],\n",
       "        [22.59710262, -2.10857709]],\n",
       "\n",
       "       [[70.51887001, -6.89375759],\n",
       "        [70.51887001, -6.89375759],\n",
       "        [70.51887001, -6.89375759],\n",
       "        ...,\n",
       "        [14.9949074 , -3.52716158],\n",
       "        [19.72988347, -0.2570724 ],\n",
       "        [22.62046321, -2.31024597]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_test.conv_(ascent2, conv_test.trained_weights)\n",
    "#convolve2d(acent2_tst,filt,boundary='symm', mode='valid' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shape = (120, 160,4)\n",
    "input_layer = pygad.cnn.Input2D(input_shape=sample_shape)\n",
    "conv_layer1 = pygad.cnn.Conv2D(num_filters=8,\n",
    "                               kernel_size=3,\n",
    "                               previous_layer=input_layer,\n",
    "                               activation_function=None)\n",
    "relu_layer1 = pygad.cnn.ReLU(previous_layer=conv_layer1)\n",
    "# average_pooling_layer = pygad.cnn.AveragePooling2D(pool_size=2,\n",
    "#                                                    previous_layer=relu_layer1,\n",
    "#                                                    stride=2)\n",
    "\n",
    "conv_layer2 = pygad.cnn.Conv2D(num_filters=16,\n",
    "                               kernel_size=3,\n",
    "                               previous_layer=relu_layer1,\n",
    "                               activation_function=None)\n",
    "relu_layer2 = pygad.cnn.ReLU(previous_layer=conv_layer2)\n",
    "# max_pooling_layer = pygad.cnn.MaxPooling2D(pool_size=2,\n",
    "#                                            previous_layer=relu_layer2,\n",
    "#                                            stride=2)\n",
    "\n",
    "conv_layer3 = pygad.cnn.Conv2D(num_filters=32,\n",
    "                               kernel_size=3,\n",
    "                               previous_layer=relu_layer2,\n",
    "                               activation_function=None)\n",
    "relu_layer3 = pygad.cnn.ReLU(previous_layer=conv_layer3)\n",
    "# pooling_layer = pygad.cnn.AveragePooling2D(pool_size=2,\n",
    "#                                            previous_layer=relu_layer3,\n",
    "#                                            stride=2)\n",
    "\n",
    "flatten_layer = pygad.cnn.Flatten(previous_layer=relu_layer3)\n",
    "dense_layer1 = pygad.cnn.Dense(num_neurons=128,\n",
    "                               previous_layer=flatten_layer,\n",
    "                               activation_function=\"relu\")\n",
    "dense_layer2 = pygad.cnn.Dense(num_neurons=num_actions,\n",
    "                               previous_layer=dense_layer1,\n",
    "                               activation_function=\"softmax\")\n",
    "\n",
    "model = pygad.cnn.Model(last_layer=dense_layer2,\n",
    "                        epochs=1,\n",
    "                        learning_rate=0.01)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer1.filter_bank_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg = np.random.rand(*sample_shape)\n",
    "ans = model.feed_sample(eg)\n",
    "print(ans)\n",
    "o = np.exp(ans)/sum(np.exp(ans))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xconv_layer1.layer_output_size)\n",
    "\n",
    "print(xrelu_layer1.layer_output_size)\n",
    "print(xaverage_pooling_layer.layer_output_size)\n",
    "print(xconv_layer2.layer_input_size)\n",
    "print(xconv_layer2.layer_output_size) #(1, 40, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xmax_pooling_layer.layer_input_size)\n",
    "print(xconv_layer3.layer_input_size)\n",
    "print(xrelu_layer3.layer_output_size)\n",
    "xflatten_layer.layer_output_size\n",
    "# xdense_layer1.layer_output_size\n",
    "# xdense_layer2.layer_output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "xinput_layer = pygad.cnn.Input2D(input_shape=input_shape)\n",
    "xconv_layer1 = pygad.cnn.Conv2D(num_filters=32,\n",
    "                               kernel_size=5,\n",
    "                               previous_layer=xinput_layer,\n",
    "                               activation_function=None)\n",
    "xrelu_layer1 = pygad.cnn.ReLU(previous_layer=xconv_layer1)\n",
    "\n",
    "\n",
    "xconv_layer2 = pygad.cnn.Conv2D(num_filters=64,\n",
    "                               kernel_size=3,\n",
    "                               previous_layer=xrelu_layer1,\n",
    "                               activation_function=None)\n",
    "xrelu_layer2 = pygad.cnn.ReLU(previous_layer=xconv_layer2)\n",
    "xconv_layer3 = pygad.cnn.Conv2D(num_filters=64,\n",
    "                               kernel_size=3,\n",
    "                               previous_layer=xrelu_layer2,\n",
    "                               activation_function=None)\n",
    "xrelu_layer3 = pygad.cnn.ReLU(previous_layer=xconv_layer3)\n",
    "\n",
    "xflatten_layer = pygad.cnn.Flatten(previous_layer=xrelu_layer3)\n",
    "xdense_layer1 = pygad.cnn.Dense(num_neurons=512,\n",
    "                               previous_layer=xflatten_layer,\n",
    "                               activation_function=\"relu\")\n",
    "xdense_layer2 = pygad.cnn.Dense(num_neurons=num_actions,\n",
    "                               previous_layer=xdense_layer1,\n",
    "                               activation_function=\"softmax\")\n",
    "\n",
    "xmodel = pygad.cnn.Model(last_layer=xdense_layer2,\n",
    "                        epochs=1,\n",
    "                        learning_rate=0.01)\n",
    "\n",
    "xmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = EvolutionaryAI(input_shape1,num_actions)\n",
    "print(m)\n",
    "z = np.random.rand(*(4, 120, 160))\n",
    "y = torch.from_numpy(z).unsqueeze(0).type('torch.FloatTensor').to('cpu')\n",
    "# m(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced = torch.jit.trace(m.cpu(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(traced, \"cpu.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = cnn.Model(last_layer=dense_layer2,learning_rate=0.0001,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(*( 120, 160,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = xmodel.feed_sample(x)\n",
    "np.exp(pr)/sum(np.exp(pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer1.initial_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_inputs=x, train_outputs=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad.gacnn as g\n",
    "\n",
    "GACNN_instance = g.GACNN(model=model, num_solutions=5)\n",
    "pop_vectors = g.population_as_vectors(population_networks=GACNN_instance.population_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_invader.util import stack_frame,preprocess_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames(frames, state, is_new=False):\n",
    "    '''\n",
    "    Function combine of utility functions to preprocess the frames\n",
    "    '''\n",
    "\n",
    "    #Preprocess the frame\n",
    "    frame = preprocess_frame(state, (160, 120))\n",
    "\n",
    "    #Stack the frame\n",
    "    frames = stack_frame(frames, frame, is_new)\n",
    "\n",
    "    #Return stacked frames\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def environment_solver(env, model):\n",
    "    '''\n",
    "    Returns a certain reward value/score that determines the fitness score/function of the neural network\n",
    "    '''\n",
    "    stacked_frames = stack_frames(None,env.reset(),True)\n",
    "    r = 0\n",
    "    s = 0\n",
    "    done = False\n",
    "\n",
    "    #Plays 1 game\n",
    "    while not done:\n",
    "        inp = torch.from_numpy(state).unsqueeze(0).type('torch.FloatTensor').to(device)\n",
    "        output_probs = agent(inp).detach().cpu().numpy()[0]\n",
    "        action = np.random.choice(range(game_actions), 1, p = output_probs).item()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = stack_frames(state, next_state, False)\n",
    "        state = next_state\n",
    "        r = r+reward\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func(solution, sol_idx):\n",
    "    global GACNN_instance\n",
    "    \n",
    "#     predictions = GACNN_instance.population_networks[sol_idx].predict(data_inputs=data_inputs)\n",
    "    model = GACNN_instance.population_networks[sol_idx]\n",
    "    \n",
    "    \n",
    "    solution_fitness = environment_solver(env,model=model)\n",
    "\n",
    "    return solution_fitness\n",
    "\n",
    "def callback_generation(ga_instance):\n",
    "    global GACNN_instance, last_fitness\n",
    "\n",
    "    population_matrices = gacnn.population_as_matrices(population_networks=GACNN_instance.population_networks,\n",
    "                                                       population_vectors=ga_instance.population)\n",
    "    GACNN_instance.update_population_trained_weights(population_trained_weights=population_matrices)\n",
    "\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parents_mating = 4\n",
    "\n",
    "num_generations = 10\n",
    "\n",
    "mutation_percent_genes = 5\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "\n",
    "crossover_type = \"single_point\"\n",
    "\n",
    "mutation_type = \"random\"\n",
    "\n",
    "keep_parents = 1\n",
    "\n",
    "init_range_low = -2\n",
    "init_range_high = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       initial_population=initial_population,\n",
    "                       fitness_func=fitness_func,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       callback_generation=callback_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.plot_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
    "print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ai_invader.model.src.activation.relu import ReluLayer\n",
    "from ai_invader.model.src.layers.pooling import MaxPoolLayer\n",
    "from ai_invader.model.src.activation.softmax import SoftmaxLayer\n",
    "from ai_invader.model.src.layers.dense import DenseLayer\n",
    "from ai_invader.model.src.layers.flatten import FlattenLayer\n",
    "from ai_invader.model.src.layers.convolutional import ConvLayer2D, SuperFastConvLayer2D\n",
    "from ai_invader.model.src.layers.dropout import DropoutLayer\n",
    "from ai_invader.model.src.model.sequential import SequentialModel\n",
    "from ai_invader.model.src.utils.core import convert_categorical2one_hot, convert_prob2categorical\n",
    "from ai_invader.model.src.utils.metrics import softmax_accuracy\n",
    "from ai_invader.model.src.optimizers.gradient_descent import GradientDescent\n",
    "from ai_invader.model.src.optimizers.rms_prop import RMSProp\n",
    "from ai_invader.model.src.optimizers.adam import Adam\n",
    "from ai_invader.model.src.utils.plots import lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples in the train data set\n",
    "N_TRAIN_SAMPLES = 50000\n",
    "# number of samples in the test data set\n",
    "N_TEST_SAMPLES = 2500\n",
    "# number of samples in the validation data set\n",
    "N_VALID_SAMPLES = 250\n",
    "# number of classes\n",
    "N_CLASSES = 10\n",
    "# image size\n",
    "IMAGE_SIZE = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "print(\"trainX shape:\", trainX.shape)\n",
    "print(\"trainY shape:\", trainY.shape)\n",
    "print(\"testX shape:\", testX.shape)\n",
    "print(\"testY shape:\", testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = trainX[:N_TRAIN_SAMPLES, :, :]\n",
    "y_train = trainY[:N_TRAIN_SAMPLES]\n",
    "\n",
    "X_test = trainX[N_TRAIN_SAMPLES:N_TRAIN_SAMPLES+N_TEST_SAMPLES, :, :]\n",
    "y_test = trainY[N_TRAIN_SAMPLES:N_TRAIN_SAMPLES+N_TEST_SAMPLES]\n",
    "\n",
    "X_valid = testX[:N_VALID_SAMPLES, :, :]\n",
    "y_valid = testY[:N_VALID_SAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_invader.model.src.base\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "y_train = convert_categorical2one_hot(y_train)\n",
    "X_test = X_test / 255\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "y_test = convert_categorical2one_hot(y_test)\n",
    "X_valid = X_valid / 255\n",
    "X_valid = np.expand_dims(X_valid, axis=3)\n",
    "y_valid = convert_categorical2one_hot(y_valid)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"y_valid shape:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0323391841137666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    'Cumulative distribution function for the standard normal distribution'\n",
    "    return (1.0 + math.erf(x / math.sqrt(2.0))) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5066487301936825"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi(1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cb4199d4da81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "min([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Orbital)",
   "language": "python",
   "name": "pycharm-a0b2edb6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
